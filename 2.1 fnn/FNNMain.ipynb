{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bahPjR3cTqaN"
   },
   "source": [
    "# Import and declaring certain arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1606383032335,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "NZqzJsCjTXu_"
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import data\n",
    "import model\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1606382636549,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "ogqV14bhTkAV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "  data = './data/wikitext-2'\n",
    "  model = 'FNNModel'\n",
    "  emsize = 200\n",
    "  context_size = 8\n",
    "  nhid = 200\n",
    "  nlayers = 2\n",
    "  lr = 20\n",
    "  clip = 0.25\n",
    "  epochs = 40\n",
    "  batch_size = 8\n",
    "  bptt = 35\n",
    "  dropout = 0.2\n",
    "  tied = True\n",
    "  seed = 1111\n",
    "  cuda = True\n",
    "  log_interval = 200\n",
    "  save = 'model.pt'\n",
    "  onnx_export = ''\n",
    "  nhead = 2\n",
    "  dry_run =  True\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1606382638140,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "x1HKajQETmPN"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os7w9It9TzTz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1606382642237,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "EVggFpzQToVN"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "corpus = data.Corpus(args.data)\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     1,     2,     3,     4,     1,     0,     0,     5,     6,\n",
      "            2,     7,     8,     9,     3,    10,    11,     8,    12,    13,\n",
      "           14,    15,     2,    16,    17,    18,     7,    19,    13,    20,\n",
      "           21,    22,    23,     2,     3,     4,    24,    25,    13,    26,\n",
      "           27,    28,    29,    30,    31,    32,    33,    34,    35,    36,\n",
      "           37,    38,    39,    17,    40,    41,    15,    42,    43,    44,\n",
      "           45,    43,    25,    13,    46,    26,    17,    47,    33,    43,\n",
      "           17,     2,    48,    15,     9,    17,    49,    50,    16,    28,\n",
      "           37,    51,    30,    52,    53,    23,    54,    55,    13,    17,\n",
      "           56,    57,    58,    22,    17,    59,    33,    37,    60,    17,\n",
      "         ...,    93,   622,    22,  5002,    78,  6656,  7628,    43,   293,\n",
      "         1043,    15,  5277,  4726,   284, 23960,    26,   494,   489,   151,\n",
      "        27535,   348,  4737,    43, 17444,    39,    17,  2532,   212,  6014,\n",
      "          212,   348,   581,   721,  7990,    15,     0,  6963, 32212,    78,\n",
      "        15399,    39,  5833,    43,   246,  4854,  2490,    15,    83,  9616,\n",
      "           26, 10660,    37,    16,   159,   915,    13,   494,    46,    26,\n",
      "            9,   310,   665,   154,     9,    15,   491, 23123,   819,    46,\n",
      "         1222,   209,     9,    61,   525,  7096,    13,   564,  1362,   151,\n",
      "         1575,   209,    61,    15,  5824,   221, 11403,  1571,    13,    46,\n",
      "         1575,   808,   209,  3083,    23,   147,  2234,  2112,    15,     0,\n",
      "            0])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(edgeitems=100)\n",
    "print(corpus.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1606382644248,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tUDx6VSxT4Dq"
   },
   "outputs": [],
   "source": [
    "# # we want to return a tensor with ascending batch \n",
    "\n",
    "# def batchify(data, bsz):\n",
    "#     # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "#     nbatch = data.size(0) // bsz\n",
    "#     # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "#     data = data.narrow(0, 0, nbatch * bsz)\n",
    "#     # Evenly divide the data across the bsz batches.\n",
    "#     data = data.view(-1, bsz).contiguous()\n",
    "#     return data.to(device)\n",
    "\n",
    "# eval_batch_size = 8\n",
    "# train_data = batchify(corpus.train, args.batch_size)\n",
    "# val_data = batchify(corpus.valid, eval_batch_size)\n",
    "# test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    value=[]\n",
    "    data = data.numpy()\n",
    "    for i,word in enumerate(data):\n",
    "        if i+bsz>= len(data):\n",
    "            # sentence boundary reached\n",
    "            # ignoring sentence less than 3 words\n",
    "            break\n",
    "        # convert word to id\n",
    "        value1 = []\n",
    "        for j in range(bsz+1):\n",
    "            value1.append(data[i+j])\n",
    "        value.append(value1)\n",
    "    value = torch.LongTensor(value)\n",
    "    return value.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 8\n",
    "train_data = batchify(corpus.train, args.context_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     1,     0,     0,     5],\n",
      "        [    1,     2,     3,     4,     1,     0,     0,     5,     6],\n",
      "        [    2,     3,     4,     1,     0,     0,     5,     6,     2],\n",
      "        [    3,     4,     1,     0,     0,     5,     6,     2,     7],\n",
      "        [    4,     1,     0,     0,     5,     6,     2,     7,     8],\n",
      "        [    1,     0,     0,     5,     6,     2,     7,     8,     9],\n",
      "        [    0,     0,     5,     6,     2,     7,     8,     9,     3],\n",
      "        [    0,     5,     6,     2,     7,     8,     9,     3,    10],\n",
      "        [    5,     6,     2,     7,     8,     9,     3,    10,    11],\n",
      "        [    6,     2,     7,     8,     9,     3,    10,    11,     8],\n",
      "        [    2,     7,     8,     9,     3,    10,    11,     8,    12],\n",
      "        [    7,     8,     9,     3,    10,    11,     8,    12,    13],\n",
      "        [    8,     9,     3,    10,    11,     8,    12,    13,    14],\n",
      "        [    9,     3,    10,    11,     8,    12,    13,    14,    15],\n",
      "        [    3,    10,    11,     8,    12,    13,    14,    15,     2],\n",
      "        [   10,    11,     8,    12,    13,    14,    15,     2,    16],\n",
      "        [   11,     8,    12,    13,    14,    15,     2,    16,    17],\n",
      "        [    8,    12,    13,    14,    15,     2,    16,    17,    18],\n",
      "        [   12,    13,    14,    15,     2,    16,    17,    18,     7],\n",
      "        [   13,    14,    15,     2,    16,    17,    18,     7,    19],\n",
      "        [   14,    15,     2,    16,    17,    18,     7,    19,    13],\n",
      "        [   15,     2,    16,    17,    18,     7,    19,    13,    20],\n",
      "        [    2,    16,    17,    18,     7,    19,    13,    20,    21],\n",
      "        [   16,    17,    18,     7,    19,    13,    20,    21,    22],\n",
      "        [   17,    18,     7,    19,    13,    20,    21,    22,    23],\n",
      "        [   18,     7,    19,    13,    20,    21,    22,    23,     2],\n",
      "        [    7,    19,    13,    20,    21,    22,    23,     2,     3],\n",
      "        [   19,    13,    20,    21,    22,    23,     2,     3,     4],\n",
      "        [   13,    20,    21,    22,    23,     2,     3,     4,    24],\n",
      "        [   20,    21,    22,    23,     2,     3,     4,    24,    25],\n",
      "        [   21,    22,    23,     2,     3,     4,    24,    25,    13],\n",
      "        [   22,    23,     2,     3,     4,    24,    25,    13,    26],\n",
      "        [   23,     2,     3,     4,    24,    25,    13,    26,    27],\n",
      "        [    2,     3,     4,    24,    25,    13,    26,    27,    28],\n",
      "        [    3,     4,    24,    25,    13,    26,    27,    28,    29],\n",
      "        [    4,    24,    25,    13,    26,    27,    28,    29,    30],\n",
      "        [   24,    25,    13,    26,    27,    28,    29,    30,    31],\n",
      "        [   25,    13,    26,    27,    28,    29,    30,    31,    32],\n",
      "        [   13,    26,    27,    28,    29,    30,    31,    32,    33],\n",
      "        [   26,    27,    28,    29,    30,    31,    32,    33,    34],\n",
      "        [   27,    28,    29,    30,    31,    32,    33,    34,    35],\n",
      "        [   28,    29,    30,    31,    32,    33,    34,    35,    36],\n",
      "        [   29,    30,    31,    32,    33,    34,    35,    36,    37],\n",
      "        [   30,    31,    32,    33,    34,    35,    36,    37,    38],\n",
      "        [   31,    32,    33,    34,    35,    36,    37,    38,    39],\n",
      "        [   32,    33,    34,    35,    36,    37,    38,    39,    17],\n",
      "        [   33,    34,    35,    36,    37,    38,    39,    17,    40],\n",
      "        [   34,    35,    36,    37,    38,    39,    17,    40,    41],\n",
      "        [   35,    36,    37,    38,    39,    17,    40,    41,    15],\n",
      "        [   36,    37,    38,    39,    17,    40,    41,    15,    42],\n",
      "        [   37,    38,    39,    17,    40,    41,    15,    42,    43],\n",
      "        [   38,    39,    17,    40,    41,    15,    42,    43,    44],\n",
      "        [   39,    17,    40,    41,    15,    42,    43,    44,    45],\n",
      "        [   17,    40,    41,    15,    42,    43,    44,    45,    43],\n",
      "        [   40,    41,    15,    42,    43,    44,    45,    43,    25],\n",
      "        [   41,    15,    42,    43,    44,    45,    43,    25,    13],\n",
      "        [   15,    42,    43,    44,    45,    43,    25,    13,    46],\n",
      "        [   42,    43,    44,    45,    43,    25,    13,    46,    26],\n",
      "        [   43,    44,    45,    43,    25,    13,    46,    26,    17],\n",
      "        [   44,    45,    43,    25,    13,    46,    26,    17,    47],\n",
      "        [   45,    43,    25,    13,    46,    26,    17,    47,    33],\n",
      "        [   43,    25,    13,    46,    26,    17,    47,    33,    43],\n",
      "        [   25,    13,    46,    26,    17,    47,    33,    43,    17],\n",
      "        [   13,    46,    26,    17,    47,    33,    43,    17,     2],\n",
      "        [   46,    26,    17,    47,    33,    43,    17,     2,    48],\n",
      "        [   26,    17,    47,    33,    43,    17,     2,    48,    15],\n",
      "        [   17,    47,    33,    43,    17,     2,    48,    15,     9],\n",
      "        [   47,    33,    43,    17,     2,    48,    15,     9,    17],\n",
      "        [   33,    43,    17,     2,    48,    15,     9,    17,    49],\n",
      "        [   43,    17,     2,    48,    15,     9,    17,    49,    50],\n",
      "        [   17,     2,    48,    15,     9,    17,    49,    50,    16],\n",
      "        [    2,    48,    15,     9,    17,    49,    50,    16,    28],\n",
      "        [   48,    15,     9,    17,    49,    50,    16,    28,    37],\n",
      "        [   15,     9,    17,    49,    50,    16,    28,    37,    51],\n",
      "        [    9,    17,    49,    50,    16,    28,    37,    51,    30],\n",
      "        [   17,    49,    50,    16,    28,    37,    51,    30,    52],\n",
      "        [   49,    50,    16,    28,    37,    51,    30,    52,    53],\n",
      "        [   50,    16,    28,    37,    51,    30,    52,    53,    23],\n",
      "        [   16,    28,    37,    51,    30,    52,    53,    23,    54],\n",
      "        [   28,    37,    51,    30,    52,    53,    23,    54,    55],\n",
      "        [   37,    51,    30,    52,    53,    23,    54,    55,    13],\n",
      "        [   51,    30,    52,    53,    23,    54,    55,    13,    17],\n",
      "        [   30,    52,    53,    23,    54,    55,    13,    17,    56],\n",
      "        [   52,    53,    23,    54,    55,    13,    17,    56,    57],\n",
      "        [   53,    23,    54,    55,    13,    17,    56,    57,    58],\n",
      "        [   23,    54,    55,    13,    17,    56,    57,    58,    22],\n",
      "        [   54,    55,    13,    17,    56,    57,    58,    22,    17],\n",
      "        [   55,    13,    17,    56,    57,    58,    22,    17,    59],\n",
      "        [   13,    17,    56,    57,    58,    22,    17,    59,    33],\n",
      "        [   17,    56,    57,    58,    22,    17,    59,    33,    37],\n",
      "        [   56,    57,    58,    22,    17,    59,    33,    37,    60],\n",
      "        [   57,    58,    22,    17,    59,    33,    37,    60,    17],\n",
      "        [   58,    22,    17,    59,    33,    37,    60,    17,    61],\n",
      "        [   22,    17,    59,    33,    37,    60,    17,    61,    62],\n",
      "        [   17,    59,    33,    37,    60,    17,    61,    62,    61],\n",
      "        [   59,    33,    37,    60,    17,    61,    62,    61,    13],\n",
      "        [   33,    37,    60,    17,    61,    62,    61,    13,    27],\n",
      "        [   37,    60,    17,    61,    62,    61,    13,    27,    63],\n",
      "        [   60,    17,    61,    62,    61,    13,    27,    63,    64],\n",
      "        [   17,    61,    62,    61,    13,    27,    63,    64,    65],\n",
      "        ...,\n",
      "        [  212,  2163,  5907,   247,   423,   310,  1399,   247,    93],\n",
      "        [ 2163,  5907,   247,   423,   310,  1399,   247,    93,   622],\n",
      "        [ 5907,   247,   423,   310,  1399,   247,    93,   622,    22],\n",
      "        [  247,   423,   310,  1399,   247,    93,   622,    22,  5002],\n",
      "        [  423,   310,  1399,   247,    93,   622,    22,  5002,    78],\n",
      "        [  310,  1399,   247,    93,   622,    22,  5002,    78,  6656],\n",
      "        [ 1399,   247,    93,   622,    22,  5002,    78,  6656,  7628],\n",
      "        [  247,    93,   622,    22,  5002,    78,  6656,  7628,    43],\n",
      "        [   93,   622,    22,  5002,    78,  6656,  7628,    43,   293],\n",
      "        [  622,    22,  5002,    78,  6656,  7628,    43,   293,  1043],\n",
      "        [   22,  5002,    78,  6656,  7628,    43,   293,  1043,    15],\n",
      "        [ 5002,    78,  6656,  7628,    43,   293,  1043,    15,  5277],\n",
      "        [   78,  6656,  7628,    43,   293,  1043,    15,  5277,  4726],\n",
      "        [ 6656,  7628,    43,   293,  1043,    15,  5277,  4726,   284],\n",
      "        [ 7628,    43,   293,  1043,    15,  5277,  4726,   284, 23960],\n",
      "        [   43,   293,  1043,    15,  5277,  4726,   284, 23960,    26],\n",
      "        [  293,  1043,    15,  5277,  4726,   284, 23960,    26,   494],\n",
      "        [ 1043,    15,  5277,  4726,   284, 23960,    26,   494,   489],\n",
      "        [   15,  5277,  4726,   284, 23960,    26,   494,   489,   151],\n",
      "        [ 5277,  4726,   284, 23960,    26,   494,   489,   151, 27535],\n",
      "        [ 4726,   284, 23960,    26,   494,   489,   151, 27535,   348],\n",
      "        [  284, 23960,    26,   494,   489,   151, 27535,   348,  4737],\n",
      "        [23960,    26,   494,   489,   151, 27535,   348,  4737,    43],\n",
      "        [   26,   494,   489,   151, 27535,   348,  4737,    43, 17444],\n",
      "        [  494,   489,   151, 27535,   348,  4737,    43, 17444,    39],\n",
      "        [  489,   151, 27535,   348,  4737,    43, 17444,    39,    17],\n",
      "        [  151, 27535,   348,  4737,    43, 17444,    39,    17,  2532],\n",
      "        [27535,   348,  4737,    43, 17444,    39,    17,  2532,   212],\n",
      "        [  348,  4737,    43, 17444,    39,    17,  2532,   212,  6014],\n",
      "        [ 4737,    43, 17444,    39,    17,  2532,   212,  6014,   212],\n",
      "        [   43, 17444,    39,    17,  2532,   212,  6014,   212,   348],\n",
      "        [17444,    39,    17,  2532,   212,  6014,   212,   348,   581],\n",
      "        [   39,    17,  2532,   212,  6014,   212,   348,   581,   721],\n",
      "        [   17,  2532,   212,  6014,   212,   348,   581,   721,  7990],\n",
      "        [ 2532,   212,  6014,   212,   348,   581,   721,  7990,    15],\n",
      "        [  212,  6014,   212,   348,   581,   721,  7990,    15,     0],\n",
      "        [ 6014,   212,   348,   581,   721,  7990,    15,     0,  6963],\n",
      "        [  212,   348,   581,   721,  7990,    15,     0,  6963, 32212],\n",
      "        [  348,   581,   721,  7990,    15,     0,  6963, 32212,    78],\n",
      "        [  581,   721,  7990,    15,     0,  6963, 32212,    78, 15399],\n",
      "        [  721,  7990,    15,     0,  6963, 32212,    78, 15399,    39],\n",
      "        [ 7990,    15,     0,  6963, 32212,    78, 15399,    39,  5833],\n",
      "        [   15,     0,  6963, 32212,    78, 15399,    39,  5833,    43],\n",
      "        [    0,  6963, 32212,    78, 15399,    39,  5833,    43,   246],\n",
      "        [ 6963, 32212,    78, 15399,    39,  5833,    43,   246,  4854],\n",
      "        [32212,    78, 15399,    39,  5833,    43,   246,  4854,  2490],\n",
      "        [   78, 15399,    39,  5833,    43,   246,  4854,  2490,    15],\n",
      "        [15399,    39,  5833,    43,   246,  4854,  2490,    15,    83],\n",
      "        [   39,  5833,    43,   246,  4854,  2490,    15,    83,  9616],\n",
      "        [ 5833,    43,   246,  4854,  2490,    15,    83,  9616,    26],\n",
      "        [   43,   246,  4854,  2490,    15,    83,  9616,    26, 10660],\n",
      "        [  246,  4854,  2490,    15,    83,  9616,    26, 10660,    37],\n",
      "        [ 4854,  2490,    15,    83,  9616,    26, 10660,    37,    16],\n",
      "        [ 2490,    15,    83,  9616,    26, 10660,    37,    16,   159],\n",
      "        [   15,    83,  9616,    26, 10660,    37,    16,   159,   915],\n",
      "        [   83,  9616,    26, 10660,    37,    16,   159,   915,    13],\n",
      "        [ 9616,    26, 10660,    37,    16,   159,   915,    13,   494],\n",
      "        [   26, 10660,    37,    16,   159,   915,    13,   494,    46],\n",
      "        [10660,    37,    16,   159,   915,    13,   494,    46,    26],\n",
      "        [   37,    16,   159,   915,    13,   494,    46,    26,     9],\n",
      "        [   16,   159,   915,    13,   494,    46,    26,     9,   310],\n",
      "        [  159,   915,    13,   494,    46,    26,     9,   310,   665],\n",
      "        [  915,    13,   494,    46,    26,     9,   310,   665,   154],\n",
      "        [   13,   494,    46,    26,     9,   310,   665,   154,     9],\n",
      "        [  494,    46,    26,     9,   310,   665,   154,     9,    15],\n",
      "        [   46,    26,     9,   310,   665,   154,     9,    15,   491],\n",
      "        [   26,     9,   310,   665,   154,     9,    15,   491, 23123],\n",
      "        [    9,   310,   665,   154,     9,    15,   491, 23123,   819],\n",
      "        [  310,   665,   154,     9,    15,   491, 23123,   819,    46],\n",
      "        [  665,   154,     9,    15,   491, 23123,   819,    46,  1222],\n",
      "        [  154,     9,    15,   491, 23123,   819,    46,  1222,   209],\n",
      "        [    9,    15,   491, 23123,   819,    46,  1222,   209,     9],\n",
      "        [   15,   491, 23123,   819,    46,  1222,   209,     9,    61],\n",
      "        [  491, 23123,   819,    46,  1222,   209,     9,    61,   525],\n",
      "        [23123,   819,    46,  1222,   209,     9,    61,   525,  7096],\n",
      "        [  819,    46,  1222,   209,     9,    61,   525,  7096,    13],\n",
      "        [   46,  1222,   209,     9,    61,   525,  7096,    13,   564],\n",
      "        [ 1222,   209,     9,    61,   525,  7096,    13,   564,  1362],\n",
      "        [  209,     9,    61,   525,  7096,    13,   564,  1362,   151],\n",
      "        [    9,    61,   525,  7096,    13,   564,  1362,   151,  1575],\n",
      "        [   61,   525,  7096,    13,   564,  1362,   151,  1575,   209],\n",
      "        [  525,  7096,    13,   564,  1362,   151,  1575,   209,    61],\n",
      "        [ 7096,    13,   564,  1362,   151,  1575,   209,    61,    15],\n",
      "        [   13,   564,  1362,   151,  1575,   209,    61,    15,  5824],\n",
      "        [  564,  1362,   151,  1575,   209,    61,    15,  5824,   221],\n",
      "        [ 1362,   151,  1575,   209,    61,    15,  5824,   221, 11403],\n",
      "        [  151,  1575,   209,    61,    15,  5824,   221, 11403,  1571],\n",
      "        [ 1575,   209,    61,    15,  5824,   221, 11403,  1571,    13],\n",
      "        [  209,    61,    15,  5824,   221, 11403,  1571,    13,    46],\n",
      "        [   61,    15,  5824,   221, 11403,  1571,    13,    46,  1575],\n",
      "        [   15,  5824,   221, 11403,  1571,    13,    46,  1575,   808],\n",
      "        [ 5824,   221, 11403,  1571,    13,    46,  1575,   808,   209],\n",
      "        [  221, 11403,  1571,    13,    46,  1575,   808,   209,  3083],\n",
      "        [11403,  1571,    13,    46,  1575,   808,   209,  3083,    23],\n",
      "        [ 1571,    13,    46,  1575,   808,   209,  3083,    23,   147],\n",
      "        [   13,    46,  1575,   808,   209,  3083,    23,   147,  2234],\n",
      "        [   46,  1575,   808,   209,  3083,    23,   147,  2234,  2112],\n",
      "        [ 1575,   808,   209,  3083,    23,   147,  2234,  2112,    15],\n",
      "        [  808,   209,  3083,    23,   147,  2234,  2112,    15,     0],\n",
      "        [  209,  3083,    23,   147,  2234,  2112,    15,     0,     0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(edgeitems=100)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DkpDwi-w2Wf"
   },
   "source": [
    "# Declaring data loader functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1606383300302,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "6_R5kUkpw0x_"
   },
   "outputs": [],
   "source": [
    "# get the train and target for the train values\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len, 0:args.context_size]\n",
    "    target = source[i+1:i+1+seq_len, args.context_size-1:args.context_size]\n",
    "    target = target.narrow(1,0,1).contiguous().view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1606382653610,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "P1VORrg9xHkO",
    "outputId": "08d4d2b6-fac8-4fe1-b4fd-252d9f91da29"
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1606382656678,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "dgp2OOLGyQz1",
    "outputId": "2535b7bb-a261-428a-e8cf-d56d489cdccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  1,  0,  0],\n",
      "        [ 1,  2,  3,  4,  1,  0,  0,  5],\n",
      "        [ 2,  3,  4,  1,  0,  0,  5,  6],\n",
      "        [ 3,  4,  1,  0,  0,  5,  6,  2],\n",
      "        [ 4,  1,  0,  0,  5,  6,  2,  7],\n",
      "        [ 1,  0,  0,  5,  6,  2,  7,  8],\n",
      "        [ 0,  0,  5,  6,  2,  7,  8,  9],\n",
      "        [ 0,  5,  6,  2,  7,  8,  9,  3],\n",
      "        [ 5,  6,  2,  7,  8,  9,  3, 10],\n",
      "        [ 6,  2,  7,  8,  9,  3, 10, 11],\n",
      "        [ 2,  7,  8,  9,  3, 10, 11,  8],\n",
      "        [ 7,  8,  9,  3, 10, 11,  8, 12],\n",
      "        [ 8,  9,  3, 10, 11,  8, 12, 13],\n",
      "        [ 9,  3, 10, 11,  8, 12, 13, 14],\n",
      "        [ 3, 10, 11,  8, 12, 13, 14, 15],\n",
      "        [10, 11,  8, 12, 13, 14, 15,  2],\n",
      "        [11,  8, 12, 13, 14, 15,  2, 16],\n",
      "        [ 8, 12, 13, 14, 15,  2, 16, 17],\n",
      "        [12, 13, 14, 15,  2, 16, 17, 18],\n",
      "        [13, 14, 15,  2, 16, 17, 18,  7],\n",
      "        [14, 15,  2, 16, 17, 18,  7, 19],\n",
      "        [15,  2, 16, 17, 18,  7, 19, 13],\n",
      "        [ 2, 16, 17, 18,  7, 19, 13, 20],\n",
      "        [16, 17, 18,  7, 19, 13, 20, 21],\n",
      "        [17, 18,  7, 19, 13, 20, 21, 22],\n",
      "        [18,  7, 19, 13, 20, 21, 22, 23],\n",
      "        [ 7, 19, 13, 20, 21, 22, 23,  2],\n",
      "        [19, 13, 20, 21, 22, 23,  2,  3],\n",
      "        [13, 20, 21, 22, 23,  2,  3,  4],\n",
      "        [20, 21, 22, 23,  2,  3,  4, 24],\n",
      "        [21, 22, 23,  2,  3,  4, 24, 25],\n",
      "        [22, 23,  2,  3,  4, 24, 25, 13],\n",
      "        [23,  2,  3,  4, 24, 25, 13, 26],\n",
      "        [ 2,  3,  4, 24, 25, 13, 26, 27],\n",
      "        [ 3,  4, 24, 25, 13, 26, 27, 28]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1606382658230,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "9t6gVANMyUhE",
    "outputId": "092d5a18-839e-436f-c166-03b82ad0a3f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  6,  2,  7,  8,  9,  3, 10, 11,  8, 12, 13, 14, 15,  2, 16, 17, 18,\n",
      "         7, 19, 13, 20, 21, 22, 23,  2,  3,  4, 24, 25, 13, 26, 27, 28, 29],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixljmNNiwzci"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1606382660333,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tws-1kW5kT39"
   },
   "outputs": [],
   "source": [
    "# creating our FNN model \n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class FNNModel(nn.Module):\n",
    "    # Here context_size should be 8( because its 8 gram model ), embedding dimension is 200, h is number of hidden layers , can set it to 200\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        # Linear 2 is the decoder that returns a variable based on vocab size \n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of all the 8 words in 8 gram model \n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn3SErKE8VWM"
   },
   "source": [
    "# Declaring the helper functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1606382660833,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "5b0MbgDyqde5"
   },
   "outputs": [],
   "source": [
    "# helper function to get accuracy from log probabilities\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, data_source):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(range(0, data_source.size(0) - 1, args.bptt)):\n",
    "            context_tensor, target_tensor = get_batch(data_source, data_tensor)\n",
    "#             context_tensor = data_tensor[:,0:2]\n",
    "#             target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPvjarqo8cis"
   },
   "source": [
    "# Training the model and evaluating on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReILiFEdqt3X",
    "outputId": "794c39a2-9b37-4f14-a567-0db7a7a94b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 10.479623794555664; Acc:0.0; Time taken (s): 0.019997358322143555| ppl 35583.02\n",
      "Training Iteration 10000 of epoch 0 complete. Loss: 6.304113864898682; Acc:0.20000000298023224; Time taken (s): 195.9660186767578| ppl   546.82\n",
      "Training Iteration 20000 of epoch 0 complete. Loss: 7.438885688781738; Acc:0.20000000298023224; Time taken (s): 196.5316503047943| ppl  1700.85\n",
      "Training Iteration 30000 of epoch 0 complete. Loss: 4.665806293487549; Acc:0.34285715222358704; Time taken (s): 196.60499715805054| ppl   106.25\n",
      "Training Iteration 40000 of epoch 0 complete. Loss: 4.848382472991943; Acc:0.37142857909202576; Time taken (s): 198.7020025253296| ppl   127.53\n",
      "Training Iteration 50000 of epoch 0 complete. Loss: 7.497588157653809; Acc:0.1428571492433548; Time taken (s): 199.93500113487244| ppl  1803.69\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.601686954498291; Mean Acc:0.20000000298023224; Time taken (s): 0.0020003318786621094\n",
      "Dev Iteration 500 complete. Mean Loss: 6.821846771620943; Mean Acc:0.1556885838508606; Time taken (s): 0.8429996967315674\n",
      "Dev Iteration 1000 complete. Mean Loss: 6.805777113397162; Mean Acc:0.1555015742778778; Time taken (s): 0.8369998931884766\n",
      "Dev Iteration 1500 complete. Mean Loss: 6.816128893902428; Mean Acc:0.15391604602336884; Time taken (s): 0.8390045166015625\n",
      "Dev Iteration 2000 complete. Mean Loss: 6.827207765121689; Mean Acc:0.15346576273441315; Time taken (s): 0.8359954357147217\n",
      "Dev Iteration 2500 complete. Mean Loss: 6.799850859007136; Mean Acc:0.1549777239561081; Time taken (s): 0.8370006084442139\n",
      "Dev Iteration 3000 complete. Mean Loss: 6.8445497229670496; Mean Acc:0.1526155322790146; Time taken (s): 0.8380036354064941\n",
      "Dev Iteration 3500 complete. Mean Loss: 6.8491998290171185; Mean Acc:0.15204596519470215; Time taken (s): 0.8339977264404297\n",
      "Dev Iteration 4000 complete. Mean Loss: 6.85504853209982; Mean Acc:0.15151149034500122; Time taken (s): 0.834998369216919\n",
      "Dev Iteration 4500 complete. Mean Loss: 6.8459224236379645; Mean Acc:0.1514386385679245; Time taken (s): 0.8389997482299805\n",
      "Dev Iteration 5000 complete. Mean Loss: 6.845488818591415; Mean Acc:0.151386097073555; Time taken (s): 0.8379995822906494\n",
      "Dev Iteration 5500 complete. Mean Loss: 6.871174386101969; Mean Acc:0.14964960515499115; Time taken (s): 0.8390014171600342\n",
      "Dev Iteration 6000 complete. Mean Loss: 6.878280352759492; Mean Acc:0.14897401630878448; Time taken (s): 0.8360028266906738\n",
      "Epoch 0 complete! Development Accuracy: 0.14856643974781036; Development Loss: 6.8839832421456295;  Development ppl: 976.5082923061252\n",
      "Best validation perplexity improved from 9999999999999999 to 976.5082923061252, saving model...\n"
     ]
    }
   ],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = FNNModel(ntokens, args.emsize, args.context_size, args.nhid).to(device)\n",
    "\n",
    "# # load it to gpu\n",
    "# model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "#define epochs\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_per= 9999999999999999\n",
    "best_model_path = None\n",
    "loss_values=[]\n",
    "ppl_values=[]\n",
    "for epoch in range(epochs):\n",
    "    st = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_ppl =0.0\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
    "        # context_tensor = data_tensor[:,0:2]\n",
    "        # target_tensor = data_tensor[:,2]\n",
    "        context_tensor, target_tensor= get_batch(train_data, data_tensor)\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #getting thw total running loss and running perplexity\n",
    "        running_loss = running_loss + loss.item()\n",
    "        running_ppl = running_ppl + math.exp(loss.item())\n",
    "\n",
    "\n",
    "        if it % 10000 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}| ppl {:8.2f}\".format(it, epoch, loss.item(), acc, (time.time()-st),  math.exp(loss.item())))\n",
    "            st = time.time()\n",
    "    \n",
    "    total_runs = math.floor((train_data.size(0) - 1)/(args.bptt))\n",
    "    loss_values.append(running_loss / total_runs)\n",
    "    ppl_values.append(running_ppl / total_runs)\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, val_data)\n",
    "    dev_per = math.exp(dev_loss)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {};  Development ppl: {}\".format(epoch, dev_acc, dev_loss, dev_per))\n",
    "    if dev_per < best_per:\n",
    "        print(\"Best validation perplexity improved from {} to {}, saving model...\".format(best_per, dev_per))\n",
    "        best_per = dev_per\n",
    "        with open(args.save, 'wb') as f:\n",
    "            torch.save(model, f)\n",
    "        # set best model path\n",
    "\n",
    "\n",
    "        \n",
    "#         best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "#         # saving best model\n",
    "#         torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261077\n",
      "35\n",
      "7459.342857142857\n"
     ]
    }
   ],
   "source": [
    "print(train_data.size(0) - 1)\n",
    "print(args.bptt)\n",
    "testa = (train_data.size(0) - 1)/(args.bptt)\n",
    "print(testa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.018658519082859357]\n"
     ]
    }
   ],
   "source": [
    "print(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7fbyTICtB/rCw/ahPljs8",
   "collapsed_sections": [],
   "name": "FNNMain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
