{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bahPjR3cTqaN"
   },
   "source": [
    "# Import and declaring certain arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1606383032335,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "NZqzJsCjTXu_"
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import data\n",
    "import model\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1606382636549,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "ogqV14bhTkAV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "  data = './data/wikitext-2'\n",
    "  model = 'FNNModel'\n",
    "  emsize = 200\n",
    "  context_size = 8\n",
    "  nhid = 200\n",
    "  nlayers = 2\n",
    "  lr = 20\n",
    "  clip = 0.25\n",
    "  epochs = 40\n",
    "  batch_size = 8\n",
    "  bptt = 35\n",
    "  dropout = 0.2\n",
    "  tied = True\n",
    "  seed = 1111\n",
    "  cuda = True\n",
    "  log_interval = 200\n",
    "  save = 'model.pt'\n",
    "  onnx_export = ''\n",
    "  nhead = 2\n",
    "  dry_run =  True\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1606382638140,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "x1HKajQETmPN"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os7w9It9TzTz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1606382642237,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "EVggFpzQToVN"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "corpus = data.Corpus(args.data)\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1606382644248,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tUDx6VSxT4Dq"
   },
   "outputs": [],
   "source": [
    "# we want to return a tensor with ascending batch \n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(-1, bsz).contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "eval_batch_size = 8\n",
    "train_data = batchify(corpus.train, args.batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DkpDwi-w2Wf"
   },
   "source": [
    "# Declaring data loader functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1606383300302,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "6_R5kUkpw0x_"
   },
   "outputs": [],
   "source": [
    "# get the train and target for the train values\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len]\n",
    "    target = target.narrow(1,0,1).contiguous().view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1606382653610,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "P1VORrg9xHkO",
    "outputId": "08d4d2b6-fac8-4fe1-b4fd-252d9f91da29"
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(val_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1606382656678,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "dgp2OOLGyQz1",
    "outputId": "2535b7bb-a261-428a-e8cf-d56d489cdccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1, 32966, 32967,     1,     0,     0, 32966],\n",
      "        [32967,    13,   406,    23,    17,  6253, 19902,   310],\n",
      "        [ 1444, 19902,    13,    26,    27,  2576,    16,     9],\n",
      "        [19902,   115,    17,  4929,  4121,  9611,    13,  4854],\n",
      "        [ 2429,    37,   651,    16,    17,   989,  2429,    15],\n",
      "        [  135,    26,  2763,   258,    22,    17,  1204, 19902],\n",
      "        [   13,  1796, 25170,    15,   135,  1575,  5357,    22],\n",
      "        [   27,   958,    16,  6318,  2584,    10,  2099,    43],\n",
      "        [   19,    37,    27,  4235,    16,  1326, 13129,    10],\n",
      "        [ 2034, 17346,    19,    13,    37,  2736,    27, 14429],\n",
      "        [ 1660,    16, 19195,    15,   652,  1127,    13,    17],\n",
      "        [19908,    78,  5710,    13,   278,  2765,    61, 19902],\n",
      "        [ 5706,    61,    93, 14706,    15, 24805,   234,    43],\n",
      "        [   17,   983,    13,  2624, 15743,   321,    78,   265],\n",
      "        [   35,    17,  2623,    39,   423,    22,    27,   152],\n",
      "        [  745, 15795,   154,     9, 15927,    15, 32966, 32967],\n",
      "        [   26,    27,   953,  9839,  5833,    13,    37,    26],\n",
      "        [ 1253,  2635,   269, 19902, 14089,    13,   464,   276],\n",
      "        [   17,  4853, 11528,    15,     0,     0,     1,     1],\n",
      "        [ 2712,     1,     1,     0,     0, 32966, 32967,    26],\n",
      "        [   27,    89,     9,    13,   119,    27,   674,   958],\n",
      "        [  423,    22,  6318,  4905,    10,  2099,    43,    19],\n",
      "        [   37, 15272,   423,    22,  1305,  1839,  1326, 13129],\n",
      "        [   10,  1721,  1839,  2034, 17346,    19,    13,   260],\n",
      "        [   17, 19908,  2635,    43, 19902, 14089,    78,  2752],\n",
      "        [  831,  1839,  3068,  2584,    10,  2585,  1839,  1215],\n",
      "        [   43,    19,  1362,    37, 15781,  1178,  1179,  2376],\n",
      "        [ 1839,  1450,  1179,  1450,  4014,    10,   998,  1179],\n",
      "        [ 1305,  1839,   173,  1179,  2585, 17346,    19,    15],\n",
      "        [  625,   225, 23965,    13, 19908,   348,    27,  4160],\n",
      "        [    9,   321,   212,  1773, 18418,    43,   472,    22],\n",
      "        [ 5357,    13,    43,    27,  5342,  1184,     9,    10],\n",
      "        [    9,    19,    15,   523,  1575,  7400,   765,   478],\n",
      "        [   27,   152,    39,   452, 19908,    13,   162, 16048],\n",
      "        [   22,   274,  3955,   998,  1839,  1450,  1193,    39]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1606382658230,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "9t6gVANMyUhE",
    "outputId": "092d5a18-839e-436f-c166-03b82ad0a3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32967,  1444, 19902,  2429,   135,    13,    27,    19,  2034,  1660,\n",
      "        19908,  5706,    17,    35,   745,    26,  1253,    17,  2712,    27,\n",
      "          423,    37,    10,    17,   831,    43,  1839,  1305,   625,     9,\n",
      "         5357,     9,    27,    22,  1803], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixljmNNiwzci"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1606382660333,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tws-1kW5kT39"
   },
   "outputs": [],
   "source": [
    "# creating our FNN model \n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class FNNModel(nn.Module):\n",
    "    # Here context_size should be 8( because its 8 gram model ), embedding dimension is 200, h is number of hidden layers , can set it to 200\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        # Linear 2 is the decoder that returns a variable based on vocab size \n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of all the 8 words in 8 gram model \n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn3SErKE8VWM"
   },
   "source": [
    "# Declaring the helper functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1606382660833,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "5b0MbgDyqde5"
   },
   "outputs": [],
   "source": [
    "# helper function to get accuracy from log probabilities\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, data_source):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(range(0, data_source.size(0) - 1, args.bptt)):\n",
    "            context_tensor, target_tensor = get_batch(data_source, data_tensor)\n",
    "#             context_tensor = data_tensor[:,0:2]\n",
    "#             target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPvjarqo8cis"
   },
   "source": [
    "# Training the model and evaluating on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReILiFEdqt3X",
    "outputId": "794c39a2-9b37-4f14-a567-0db7a7a94b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 10.415826797485352; Acc:0.0; Time taken (s): 0.025999784469604492\n",
      "Training Iteration 500 of epoch 0 complete. Loss: 7.913747787475586; Acc:0.05714285746216774; Time taken (s): 9.69129228591919\n",
      "Training Iteration 1000 of epoch 0 complete. Loss: 7.659245014190674; Acc:0.08571428805589676; Time taken (s): 9.512871265411377\n",
      "Training Iteration 1500 of epoch 0 complete. Loss: 6.841477394104004; Acc:0.05714285746216774; Time taken (s): 9.611093282699585\n",
      "Training Iteration 2000 of epoch 0 complete. Loss: 7.148714542388916; Acc:0.11428571492433548; Time taken (s): 9.513012647628784\n",
      "Training Iteration 2500 of epoch 0 complete. Loss: 7.958803653717041; Acc:0.11428571492433548; Time taken (s): 9.50612759590149\n",
      "Training Iteration 3000 of epoch 0 complete. Loss: 7.782478332519531; Acc:0.20000000298023224; Time taken (s): 9.48199462890625\n",
      "Training Iteration 3500 of epoch 0 complete. Loss: 6.828896522521973; Acc:0.11428571492433548; Time taken (s): 9.483431339263916\n",
      "Training Iteration 4000 of epoch 0 complete. Loss: 8.967962265014648; Acc:0.02857142873108387; Time taken (s): 9.476235628128052\n",
      "Training Iteration 4500 of epoch 0 complete. Loss: 5.1281609535217285; Acc:0.3142857253551483; Time taken (s): 9.494243860244751\n",
      "Training Iteration 5000 of epoch 0 complete. Loss: 7.320188522338867; Acc:0.1428571492433548; Time taken (s): 9.536818504333496\n",
      "Training Iteration 5500 of epoch 0 complete. Loss: 6.907042503356934; Acc:0.20000000298023224; Time taken (s): 9.47668981552124\n",
      "Training Iteration 6000 of epoch 0 complete. Loss: 6.54565954208374; Acc:0.22857142984867096; Time taken (s): 9.483789205551147\n",
      "Training Iteration 6500 of epoch 0 complete. Loss: 7.181065559387207; Acc:0.2571428716182709; Time taken (s): 9.483959436416626\n",
      "Training Iteration 7000 of epoch 0 complete. Loss: 8.081727027893066; Acc:0.11428571492433548; Time taken (s): 9.481276273727417\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 6.007806777954102; Mean Acc:0.17142857611179352; Time taken (s): 1.2881789207458496\n",
      "Dev Iteration 500 complete. Mean Loss: 6.791368414066033; Mean Acc:0.14291398227214813; Time taken (s): 0.8369824886322021\n",
      "Epoch 0 complete! Development Accuracy: 0.138625830411911; Development Loss: 6.833789564649979\n",
      "Best development accuracy improved from 0 to 0.138625830411911, saving model...\n",
      "\n",
      "--- Training model Epoch: 2 ---\n",
      "Training Iteration 0 of epoch 1 complete. Loss: 6.283180236816406; Acc:0.17142857611179352; Time taken (s): 0.02100205421447754\n",
      "Training Iteration 500 of epoch 1 complete. Loss: 7.060035228729248; Acc:0.05714285746216774; Time taken (s): 9.529634237289429\n",
      "Training Iteration 1000 of epoch 1 complete. Loss: 5.975159645080566; Acc:0.11428571492433548; Time taken (s): 9.51506519317627\n",
      "Training Iteration 1500 of epoch 1 complete. Loss: 6.076370716094971; Acc:0.08571428805589676; Time taken (s): 9.520999908447266\n",
      "Training Iteration 2000 of epoch 1 complete. Loss: 6.232204437255859; Acc:0.1428571492433548; Time taken (s): 9.600024223327637\n",
      "Training Iteration 2500 of epoch 1 complete. Loss: 6.877999305725098; Acc:0.1428571492433548; Time taken (s): 9.625767469406128\n",
      "Training Iteration 3000 of epoch 1 complete. Loss: 6.638671398162842; Acc:0.1428571492433548; Time taken (s): 9.606498718261719\n",
      "Training Iteration 3500 of epoch 1 complete. Loss: 5.954477310180664; Acc:0.17142857611179352; Time taken (s): 9.648163557052612\n",
      "Training Iteration 4000 of epoch 1 complete. Loss: 7.015485763549805; Acc:0.11428571492433548; Time taken (s): 9.491263628005981\n",
      "Training Iteration 4500 of epoch 1 complete. Loss: 4.465885639190674; Acc:0.2857142984867096; Time taken (s): 9.629443168640137\n",
      "Training Iteration 5000 of epoch 1 complete. Loss: 5.891559600830078; Acc:0.1428571492433548; Time taken (s): 9.697474002838135\n",
      "Training Iteration 5500 of epoch 1 complete. Loss: 5.292158603668213; Acc:0.1428571492433548; Time taken (s): 9.542731523513794\n",
      "Training Iteration 6000 of epoch 1 complete. Loss: 4.799993991851807; Acc:0.2571428716182709; Time taken (s): 9.664160966873169\n",
      "Training Iteration 6500 of epoch 1 complete. Loss: 5.863771915435791; Acc:0.20000000298023224; Time taken (s): 9.61623740196228\n",
      "Training Iteration 7000 of epoch 1 complete. Loss: 5.998717308044434; Acc:0.17142857611179352; Time taken (s): 9.564351320266724\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.886683464050293; Mean Acc:0.22857142984867096; Time taken (s): 1.2859976291656494\n",
      "Dev Iteration 500 complete. Mean Loss: 6.937069313254899; Mean Acc:0.14302819967269897; Time taken (s): 0.8379991054534912\n",
      "Epoch 1 complete! Development Accuracy: 0.13811591267585754; Development Loss: 6.985699157481942\n",
      "\n",
      "--- Training model Epoch: 3 ---\n",
      "Training Iteration 0 of epoch 2 complete. Loss: 5.376170635223389; Acc:0.17142857611179352; Time taken (s): 0.019995927810668945\n",
      "Training Iteration 500 of epoch 2 complete. Loss: 5.708851337432861; Acc:0.17142857611179352; Time taken (s): 9.534657001495361\n",
      "Training Iteration 1000 of epoch 2 complete. Loss: 4.826937198638916; Acc:0.17142857611179352; Time taken (s): 9.524667263031006\n",
      "Training Iteration 1500 of epoch 2 complete. Loss: 5.185423851013184; Acc:0.05714285746216774; Time taken (s): 9.591962575912476\n",
      "Training Iteration 2000 of epoch 2 complete. Loss: 5.476462364196777; Acc:0.17142857611179352; Time taken (s): 9.555733442306519\n",
      "Training Iteration 2500 of epoch 2 complete. Loss: 5.5606865882873535; Acc:0.11428571492433548; Time taken (s): 9.677727222442627\n",
      "Training Iteration 3000 of epoch 2 complete. Loss: 5.1488823890686035; Acc:0.1428571492433548; Time taken (s): 9.669341325759888\n",
      "Training Iteration 3500 of epoch 2 complete. Loss: 5.711626052856445; Acc:0.1428571492433548; Time taken (s): 9.719856023788452\n",
      "Training Iteration 4000 of epoch 2 complete. Loss: 5.3834309577941895; Acc:0.11428571492433548; Time taken (s): 9.768184185028076\n",
      "Training Iteration 4500 of epoch 2 complete. Loss: 3.940535545349121; Acc:0.3142857253551483; Time taken (s): 9.831242561340332\n",
      "Training Iteration 5000 of epoch 2 complete. Loss: 4.993782043457031; Acc:0.17142857611179352; Time taken (s): 9.587652444839478\n",
      "Training Iteration 5500 of epoch 2 complete. Loss: 4.384324550628662; Acc:0.2857142984867096; Time taken (s): 9.593002557754517\n",
      "Training Iteration 6000 of epoch 2 complete. Loss: 3.6896655559539795; Acc:0.3142857253551483; Time taken (s): 9.613802433013916\n",
      "Training Iteration 6500 of epoch 2 complete. Loss: 5.217759609222412; Acc:0.22857142984867096; Time taken (s): 9.620021104812622\n",
      "Training Iteration 7000 of epoch 2 complete. Loss: 5.051109790802002; Acc:0.1428571492433548; Time taken (s): 9.508140325546265\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 6.410297870635986; Mean Acc:0.20000000298023224; Time taken (s): 1.286393165588379\n",
      "Dev Iteration 500 complete. Mean Loss: 7.243727330914038; Mean Acc:0.1405189484357834; Time taken (s): 0.8440008163452148\n",
      "Epoch 2 complete! Development Accuracy: 0.13616132736206055; Development Loss: 7.300046324423469\n",
      "\n",
      "--- Training model Epoch: 4 ---\n",
      "Training Iteration 0 of epoch 3 complete. Loss: 4.804723262786865; Acc:0.20000000298023224; Time taken (s): 0.018993854522705078\n",
      "Training Iteration 500 of epoch 3 complete. Loss: 4.223060607910156; Acc:0.2571428716182709; Time taken (s): 9.624232769012451\n",
      "Training Iteration 1000 of epoch 3 complete. Loss: 4.221555233001709; Acc:0.17142857611179352; Time taken (s): 9.587733745574951\n",
      "Training Iteration 1500 of epoch 3 complete. Loss: 4.599181652069092; Acc:0.17142857611179352; Time taken (s): 9.701064109802246\n",
      "Training Iteration 2000 of epoch 3 complete. Loss: 4.593973159790039; Acc:0.17142857611179352; Time taken (s): 9.682697057723999\n",
      "Training Iteration 2500 of epoch 3 complete. Loss: 4.630977153778076; Acc:0.20000000298023224; Time taken (s): 9.610487461090088\n",
      "Training Iteration 3000 of epoch 3 complete. Loss: 4.368292808532715; Acc:0.34285715222358704; Time taken (s): 9.611170291900635\n",
      "Training Iteration 3500 of epoch 3 complete. Loss: 5.396360874176025; Acc:0.1428571492433548; Time taken (s): 9.695338010787964\n",
      "Training Iteration 4000 of epoch 3 complete. Loss: 4.145041465759277; Acc:0.2857142984867096; Time taken (s): 9.762323141098022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 4500 of epoch 3 complete. Loss: 3.4208340644836426; Acc:0.3142857253551483; Time taken (s): 9.53130555152893\n",
      "Training Iteration 5000 of epoch 3 complete. Loss: 4.174997806549072; Acc:0.20000000298023224; Time taken (s): 9.646984577178955\n",
      "Training Iteration 5500 of epoch 3 complete. Loss: 3.7479069232940674; Acc:0.4000000059604645; Time taken (s): 9.560098886489868\n",
      "Training Iteration 6000 of epoch 3 complete. Loss: 2.9953224658966064; Acc:0.4571428596973419; Time taken (s): 9.545814037322998\n",
      "Training Iteration 6500 of epoch 3 complete. Loss: 4.420825004577637; Acc:0.2571428716182709; Time taken (s): 9.632787227630615\n",
      "Training Iteration 7000 of epoch 3 complete. Loss: 3.613224506378174; Acc:0.2857142984867096; Time taken (s): 9.66140079498291\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 6.813724994659424; Mean Acc:0.17142857611179352; Time taken (s): 1.2915005683898926\n",
      "Dev Iteration 500 complete. Mean Loss: 7.575576219730035; Mean Acc:0.13384640216827393; Time taken (s): 0.8450355529785156\n",
      "Epoch 3 complete! Development Accuracy: 0.13075865805149078; Development Loss: 7.630470116524586\n",
      "\n",
      "--- Training model Epoch: 5 ---\n",
      "Training Iteration 0 of epoch 4 complete. Loss: 3.8694746494293213; Acc:0.2571428716182709; Time taken (s): 0.02000260353088379\n",
      "Training Iteration 500 of epoch 4 complete. Loss: 3.2360053062438965; Acc:0.4571428596973419; Time taken (s): 9.584366798400879\n",
      "Training Iteration 1000 of epoch 4 complete. Loss: 3.2982823848724365; Acc:0.34285715222358704; Time taken (s): 9.541854858398438\n",
      "Training Iteration 1500 of epoch 4 complete. Loss: 3.8275704383850098; Acc:0.2857142984867096; Time taken (s): 9.484915971755981\n",
      "Training Iteration 2000 of epoch 4 complete. Loss: 3.5661375522613525; Acc:0.34285715222358704; Time taken (s): 9.522655963897705\n",
      "Training Iteration 2500 of epoch 4 complete. Loss: 4.11310338973999; Acc:0.2571428716182709; Time taken (s): 9.578406810760498\n",
      "Training Iteration 3000 of epoch 4 complete. Loss: 3.466590404510498; Acc:0.37142857909202576; Time taken (s): 9.694475650787354\n",
      "Training Iteration 3500 of epoch 4 complete. Loss: 4.725275039672852; Acc:0.20000000298023224; Time taken (s): 9.667410850524902\n",
      "Training Iteration 4000 of epoch 4 complete. Loss: 3.718966245651245; Acc:0.34285715222358704; Time taken (s): 9.535159349441528\n",
      "Training Iteration 4500 of epoch 4 complete. Loss: 3.1910104751586914; Acc:0.37142857909202576; Time taken (s): 9.540820121765137\n"
     ]
    }
   ],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = FNNModel(ntokens, args.emsize, args.context_size, args.nhid).to(device)\n",
    "\n",
    "# # load it to gpu\n",
    "# model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_model_path = None\n",
    "for epoch in range(5):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(range(0, train_data.size(0) - 1, args.bptt)):       \n",
    "        # context_tensor = data_tensor[:,0:2]\n",
    "        # target_tensor = data_tensor[:,2]\n",
    "        context_tensor, target_tensor= get_batch(train_data, data_tensor)\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, val_data)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(epoch, dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # set best model path\n",
    "        best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "        # saving best model\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cacnBkP9yBcd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7fbyTICtB/rCw/ahPljs8",
   "collapsed_sections": [],
   "name": "FNNMain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
