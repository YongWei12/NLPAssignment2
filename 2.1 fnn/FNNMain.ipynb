{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bahPjR3cTqaN"
   },
   "source": [
    "# Import and declaring certain arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1606383032335,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "NZqzJsCjTXu_"
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import data\n",
    "import model\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1606382636549,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "ogqV14bhTkAV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "  data = './data/wikitext-2'\n",
    "  model = 'FNNModel'\n",
    "  emsize = 200\n",
    "  context_size = 8\n",
    "  nhid = 200\n",
    "  nlayers = 2\n",
    "  lr = 20\n",
    "  clip = 0.25\n",
    "  epochs = 40\n",
    "  batch_size = 8\n",
    "  bptt = 35\n",
    "  dropout = 0.2\n",
    "  tied = True\n",
    "  seed = 1111\n",
    "  cuda = True\n",
    "  log_interval = 200\n",
    "  save = 'model.pt'\n",
    "  onnx_export = ''\n",
    "  nhead = 2\n",
    "  dry_run =  True\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1606382638140,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "x1HKajQETmPN"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os7w9It9TzTz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1606382642237,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "EVggFpzQToVN"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "corpus = data.Corpus(args.data)\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1606382644248,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tUDx6VSxT4Dq"
   },
   "outputs": [],
   "source": [
    "# we want to return a tensor with ascending batch \n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(-1, bsz).contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "eval_batch_size = 8\n",
    "train_data = batchify(corpus.train, args.batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DkpDwi-w2Wf"
   },
   "source": [
    "# Declaring data loader functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1606383300302,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "6_R5kUkpw0x_"
   },
   "outputs": [],
   "source": [
    "# get the train and target for the train values\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len]\n",
    "    target = target.narrow(1,0,1).contiguous().view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1606382653610,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "P1VORrg9xHkO",
    "outputId": "08d4d2b6-fac8-4fe1-b4fd-252d9f91da29"
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1606382656678,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "dgp2OOLGyQz1",
    "outputId": "2535b7bb-a261-428a-e8cf-d56d489cdccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2,   3,   4,   1,   0,   0],\n",
      "        [  5,   6,   2,   7,   8,   9,   3,  10],\n",
      "        [ 11,   8,  12,  13,  14,  15,   2,  16],\n",
      "        [ 17,  18,   7,  19,  13,  20,  21,  22],\n",
      "        [ 23,   2,   3,   4,  24,  25,  13,  26],\n",
      "        [ 27,  28,  29,  30,  31,  32,  33,  34],\n",
      "        [ 35,  36,  37,  38,  39,  17,  40,  41],\n",
      "        [ 15,  42,  43,  44,  45,  43,  25,  13],\n",
      "        [ 46,  26,  17,  47,  33,  43,  17,   2],\n",
      "        [ 48,  15,   9,  17,  49,  50,  16,  28],\n",
      "        [ 37,  51,  30,  52,  53,  23,  54,  55],\n",
      "        [ 13,  17,  56,  57,  58,  22,  17,  59],\n",
      "        [ 33,  37,  60,  17,  61,  62,  61,  13],\n",
      "        [ 27,  63,  64,  65,  66,  17,  67,  16],\n",
      "        [ 68,  69,  17,  70,  71,  72,  73,  74],\n",
      "        [ 75,  76,  77,  37,  78,  79,  80,  17],\n",
      "        [ 81,  65,  61,   9,  82,  61,  15,   0],\n",
      "        [ 83,  33,  84,  85,  43,  86,  13,  87],\n",
      "        [ 88,  27,  89,  90,  16,  17,  91,  92],\n",
      "        [ 93,   2,   3,  94,  15,  95,  46,  96],\n",
      "        [ 17,  97,  98,  16,  17,  48,  13,  46],\n",
      "        [ 99, 100, 101, 102,  13, 103,  23, 104],\n",
      "        [ 17,  33, 105,   9,  39,  48, 106,  15],\n",
      "        [107, 108,   9, 109,  37, 110, 111, 112],\n",
      "        [113, 114, 115, 116, 117,  13, 118, 119],\n",
      "        [  2,   3,  94, 120, 121, 122,  15, 123],\n",
      "        [ 89, 124,  16, 125, 126,  17, 127,  15],\n",
      "        [ 83,  33, 128, 129, 130, 131, 132,  35],\n",
      "        [133, 134,  15,   0, 135, 136, 119, 137],\n",
      "        [138,  43,  25,  13,  37, 131, 139,  35],\n",
      "        [113,  11,  37, 140, 141,  15, 142, 143],\n",
      "        [ 13,  46, 144, 145, 146,  13, 118, 119],\n",
      "        [147, 148, 149,  43, 150,  16, 151, 152],\n",
      "        [ 15, 135, 131,  99, 153, 154, 155,  37],\n",
      "        [147, 156,  32, 157,  48,  15, 158,  22]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1606382658230,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "9t6gVANMyUhE",
    "outputId": "092d5a18-839e-436f-c166-03b82ad0a3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5,  11,  17,  23,  27,  35,  15,  46,  48,  37,  13,  33,  27,  68,\n",
      "         75,  81,  83,  88,  93,  17,  99,  17, 107, 113,   2,  89,  83, 133,\n",
      "        138, 113,  13, 147,  15, 147, 159], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixljmNNiwzci"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1606382660333,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tws-1kW5kT39"
   },
   "outputs": [],
   "source": [
    "# creating our FNN model \n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class FNNModel(nn.Module):\n",
    "    # Here context_size should be 8( because its 8 gram model ), embedding dimension is 200, h is number of hidden layers , can set it to 200\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        # Linear 2 is the decoder that returns a variable based on vocab size \n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of all the 8 words in 8 gram model \n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn3SErKE8VWM"
   },
   "source": [
    "# Declaring the helper functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1606382660833,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "5b0MbgDyqde5"
   },
   "outputs": [],
   "source": [
    "# helper function to get accuracy from log probabilities\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, dataloader, gpu):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(dataloader):\n",
    "            context_tensor = data_tensor[:,0:2]\n",
    "            target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPvjarqo8cis"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReILiFEdqt3X",
    "outputId": "794c39a2-9b37-4f14-a567-0db7a7a94b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 10.429022789001465; Acc:0.0; Time taken (s): 1.6938209533691406\n",
      "Training Iteration 500 of epoch 0 complete. Loss: 8.245803833007812; Acc:0.02857142873108387; Time taken (s): 9.499763011932373\n",
      "Training Iteration 1000 of epoch 0 complete. Loss: 7.6052656173706055; Acc:0.1428571492433548; Time taken (s): 9.596279382705688\n",
      "Training Iteration 1500 of epoch 0 complete. Loss: 7.178322792053223; Acc:0.05714285746216774; Time taken (s): 9.51860499382019\n",
      "Training Iteration 2000 of epoch 0 complete. Loss: 7.172187328338623; Acc:0.1428571492433548; Time taken (s): 9.695068120956421\n",
      "Training Iteration 2500 of epoch 0 complete. Loss: 7.939382553100586; Acc:0.08571428805589676; Time taken (s): 9.542513847351074\n",
      "Training Iteration 3000 of epoch 0 complete. Loss: 8.121339797973633; Acc:0.20000000298023224; Time taken (s): 9.536884307861328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cfc619caee56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# calculate current accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy_from_log_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# compute loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-4764aae0bbc0>\u001b[0m in \u001b[0;36mget_accuracy_from_log_probs\u001b[1;34m(log_probs, labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = FNNModel(ntokens, args.emsize, args.context_size, args.nhid).to(device)\n",
    "\n",
    "# # load it to gpu\n",
    "# model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_model_path = None\n",
    "for epoch in range(5):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(range(0, train_data.size(0) - 1, args.bptt)):       \n",
    "        # context_tensor = data_tensor[:,0:2]\n",
    "        # target_tensor = data_tensor[:,2]\n",
    "        context_tensor, target_tensor= get_batch(train_data, data_tensor)\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, dev_loader, gpu)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(epoch, dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # set best model path\n",
    "        best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "        # saving best model\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cacnBkP9yBcd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7fbyTICtB/rCw/ahPljs8",
   "collapsed_sections": [],
   "name": "FNNMain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
