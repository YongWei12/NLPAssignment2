{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bahPjR3cTqaN"
   },
   "source": [
    "# Import and declaring certain arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1606383032335,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "NZqzJsCjTXu_"
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import data\n",
    "import model\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1606382636549,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "ogqV14bhTkAV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "  data = './data/wikitext-2'\n",
    "  model = 'FNNModel'\n",
    "  emsize = 200\n",
    "  context_size = 8\n",
    "  nhid = 200\n",
    "  nlayers = 2\n",
    "  lr = 20\n",
    "  clip = 0.25\n",
    "  epochs = 40\n",
    "  batch_size = 8\n",
    "  bptt = 35\n",
    "  dropout = 0.2\n",
    "  tied = True\n",
    "  seed = 1111\n",
    "  cuda = True\n",
    "  log_interval = 200\n",
    "  save = 'model.pt'\n",
    "  onnx_export = ''\n",
    "  nhead = 2\n",
    "  dry_run =  True\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1606382638140,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "x1HKajQETmPN"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os7w9It9TzTz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1606382642237,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "EVggFpzQToVN"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "corpus = data.Corpus(args.data)\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1606382644248,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tUDx6VSxT4Dq"
   },
   "outputs": [],
   "source": [
    "# we want to return a tensor with ascending batch \n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(-1, bsz).contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "eval_batch_size = 8\n",
    "train_data = batchify(corpus.train, args.batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DkpDwi-w2Wf"
   },
   "source": [
    "# Declaring data loader functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1606383300302,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "6_R5kUkpw0x_"
   },
   "outputs": [],
   "source": [
    "# get the train and target for the train values\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len]\n",
    "    target = target.narrow(1,0,1).contiguous().view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1606382653610,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "P1VORrg9xHkO",
    "outputId": "08d4d2b6-fac8-4fe1-b4fd-252d9f91da29"
   },
   "outputs": [],
   "source": [
    "data, target = get_batch(val_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1606382656678,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "dgp2OOLGyQz1",
    "outputId": "2535b7bb-a261-428a-e8cf-d56d489cdccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1, 32966, 32967,     1,     0,     0, 32966],\n",
      "        [32967,    13,   406,    23,    17,  6253, 19902,   310],\n",
      "        [ 1444, 19902,    13,    26,    27,  2576,    16,     9],\n",
      "        [19902,   115,    17,  4929,  4121,  9611,    13,  4854],\n",
      "        [ 2429,    37,   651,    16,    17,   989,  2429,    15],\n",
      "        [  135,    26,  2763,   258,    22,    17,  1204, 19902],\n",
      "        [   13,  1796, 25170,    15,   135,  1575,  5357,    22],\n",
      "        [   27,   958,    16,  6318,  2584,    10,  2099,    43],\n",
      "        [   19,    37,    27,  4235,    16,  1326, 13129,    10],\n",
      "        [ 2034, 17346,    19,    13,    37,  2736,    27, 14429],\n",
      "        [ 1660,    16, 19195,    15,   652,  1127,    13,    17],\n",
      "        [19908,    78,  5710,    13,   278,  2765,    61, 19902],\n",
      "        [ 5706,    61,    93, 14706,    15, 24805,   234,    43],\n",
      "        [   17,   983,    13,  2624, 15743,   321,    78,   265],\n",
      "        [   35,    17,  2623,    39,   423,    22,    27,   152],\n",
      "        [  745, 15795,   154,     9, 15927,    15, 32966, 32967],\n",
      "        [   26,    27,   953,  9839,  5833,    13,    37,    26],\n",
      "        [ 1253,  2635,   269, 19902, 14089,    13,   464,   276],\n",
      "        [   17,  4853, 11528,    15,     0,     0,     1,     1],\n",
      "        [ 2712,     1,     1,     0,     0, 32966, 32967,    26],\n",
      "        [   27,    89,     9,    13,   119,    27,   674,   958],\n",
      "        [  423,    22,  6318,  4905,    10,  2099,    43,    19],\n",
      "        [   37, 15272,   423,    22,  1305,  1839,  1326, 13129],\n",
      "        [   10,  1721,  1839,  2034, 17346,    19,    13,   260],\n",
      "        [   17, 19908,  2635,    43, 19902, 14089,    78,  2752],\n",
      "        [  831,  1839,  3068,  2584,    10,  2585,  1839,  1215],\n",
      "        [   43,    19,  1362,    37, 15781,  1178,  1179,  2376],\n",
      "        [ 1839,  1450,  1179,  1450,  4014,    10,   998,  1179],\n",
      "        [ 1305,  1839,   173,  1179,  2585, 17346,    19,    15],\n",
      "        [  625,   225, 23965,    13, 19908,   348,    27,  4160],\n",
      "        [    9,   321,   212,  1773, 18418,    43,   472,    22],\n",
      "        [ 5357,    13,    43,    27,  5342,  1184,     9,    10],\n",
      "        [    9,    19,    15,   523,  1575,  7400,   765,   478],\n",
      "        [   27,   152,    39,   452, 19908,    13,   162, 16048],\n",
      "        [   22,   274,  3955,   998,  1839,  1450,  1193,    39]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1606382658230,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "9t6gVANMyUhE",
    "outputId": "092d5a18-839e-436f-c166-03b82ad0a3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32967,  1444, 19902,  2429,   135,    13,    27,    19,  2034,  1660,\n",
      "        19908,  5706,    17,    35,   745,    26,  1253,    17,  2712,    27,\n",
      "          423,    37,    10,    17,   831,    43,  1839,  1305,   625,     9,\n",
      "         5357,     9,    27,    22,  1803], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixljmNNiwzci"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1606382660333,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "tws-1kW5kT39"
   },
   "outputs": [],
   "source": [
    "# creating our FNN model \n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class FNNModel(nn.Module):\n",
    "    # Here context_size should be 8( because its 8 gram model ), embedding dimension is 200, h is number of hidden layers , can set it to 200\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        # Linear 2 is the decoder that returns a variable based on vocab size \n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of all the 8 words in 8 gram model \n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn3SErKE8VWM"
   },
   "source": [
    "# Declaring the helper functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1606382660833,
     "user": {
      "displayName": "yong wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYJ6D3p-i8GPWEqh4u2s4VniV_lHZd6l3-eHSaqA=s64",
      "userId": "07110467073693299033"
     },
     "user_tz": -480
    },
    "id": "5b0MbgDyqde5"
   },
   "outputs": [],
   "source": [
    "# helper function to get accuracy from log probabilities\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, data_source):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(range(0, data_source.size(0) - 1, args.bptt)):\n",
    "            context_tensor, target_tensor = get_batch(data_source, data_tensor)\n",
    "#             context_tensor = data_tensor[:,0:2]\n",
    "#             target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPvjarqo8cis"
   },
   "source": [
    "# Training the model and evaluating on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReILiFEdqt3X",
    "outputId": "794c39a2-9b37-4f14-a567-0db7a7a94b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 10.463059425354004; Acc:0.0; Time taken (s): 0.22399425506591797\n",
      "Training Iteration 500 of epoch 0 complete. Loss: 8.046185493469238; Acc:0.05714285746216774; Time taken (s): 9.512906074523926\n",
      "Training Iteration 1000 of epoch 0 complete. Loss: 7.356433868408203; Acc:0.08571428805589676; Time taken (s): 9.538431644439697\n",
      "Training Iteration 1500 of epoch 0 complete. Loss: 7.026973247528076; Acc:0.05714285746216774; Time taken (s): 9.492260456085205\n",
      "Training Iteration 2000 of epoch 0 complete. Loss: 7.165158748626709; Acc:0.17142857611179352; Time taken (s): 9.497876405715942\n",
      "Training Iteration 2500 of epoch 0 complete. Loss: 7.949654579162598; Acc:0.11428571492433548; Time taken (s): 9.490994453430176\n",
      "Training Iteration 3000 of epoch 0 complete. Loss: 7.928435325622559; Acc:0.17142857611179352; Time taken (s): 9.47422194480896\n",
      "Training Iteration 3500 of epoch 0 complete. Loss: 7.0991644859313965; Acc:0.08571428805589676; Time taken (s): 9.472280263900757\n",
      "Training Iteration 4000 of epoch 0 complete. Loss: 9.015541076660156; Acc:0.02857142873108387; Time taken (s): 9.47333550453186\n",
      "Training Iteration 4500 of epoch 0 complete. Loss: 5.036379814147949; Acc:0.3142857253551483; Time taken (s): 9.48002815246582\n",
      "Training Iteration 5000 of epoch 0 complete. Loss: 6.729080677032471; Acc:0.17142857611179352; Time taken (s): 9.477285146713257\n",
      "Training Iteration 5500 of epoch 0 complete. Loss: 7.3669233322143555; Acc:0.08571428805589676; Time taken (s): 9.556318998336792\n",
      "Training Iteration 6000 of epoch 0 complete. Loss: 6.513754367828369; Acc:0.17142857611179352; Time taken (s): 9.504420042037964\n",
      "Training Iteration 6500 of epoch 0 complete. Loss: 7.234570026397705; Acc:0.17142857611179352; Time taken (s): 9.476915121078491\n",
      "Training Iteration 7000 of epoch 0 complete. Loss: 7.890047550201416; Acc:0.1428571492433548; Time taken (s): 9.617761135101318\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 6.287730693817139; Mean Acc:0.1428571492433548; Time taken (s): 1.2989988327026367\n",
      "Dev Iteration 500 complete. Mean Loss: 6.742163100404416; Mean Acc:0.13909314572811127; Time taken (s): 0.8430156707763672\n",
      "Epoch 0 complete! Development Accuracy: 0.13686303794384003; Development Loss: 6.779893020431302\n",
      "Best development accuracy improved from 0 to 0.13686303794384003, saving model...\n",
      "\n",
      "--- Training model Epoch: 2 ---\n",
      "Training Iteration 0 of epoch 1 complete. Loss: 6.377782821655273; Acc:0.1428571492433548; Time taken (s): 0.020999908447265625\n",
      "Training Iteration 500 of epoch 1 complete. Loss: 6.793476104736328; Acc:0.05714285746216774; Time taken (s): 9.532023191452026\n",
      "Training Iteration 1000 of epoch 1 complete. Loss: 6.131345272064209; Acc:0.20000000298023224; Time taken (s): 9.531105041503906\n",
      "Training Iteration 1500 of epoch 1 complete. Loss: 6.602681636810303; Acc:0.08571428805589676; Time taken (s): 9.564893245697021\n",
      "Training Iteration 2000 of epoch 1 complete. Loss: 6.117618560791016; Acc:0.1428571492433548; Time taken (s): 9.516202211380005\n",
      "Training Iteration 2500 of epoch 1 complete. Loss: 6.270486354827881; Acc:0.11428571492433548; Time taken (s): 9.530593395233154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d6fcc6c653d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# get log probabilities over next words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# calculate current accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yongwei\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-13bd018a8aad>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# compute h: tanh(W_1.x' + b)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m# compute W_2.h\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yongwei\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yongwei\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yongwei\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = FNNModel(ntokens, args.emsize, args.context_size, args.nhid).to(device)\n",
    "\n",
    "# # load it to gpu\n",
    "# model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_model_path = None\n",
    "for epoch in range(5):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(range(0, train_data.size(0) - 1, args.bptt)):       \n",
    "        # context_tensor = data_tensor[:,0:2]\n",
    "        # target_tensor = data_tensor[:,2]\n",
    "        context_tensor, target_tensor= get_batch(train_data, data_tensor)\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, val_data)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(epoch, dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        with open(args.save, 'wb') as f:\n",
    "            torch.save(model, f)\n",
    "        # set best model path\n",
    "\n",
    "\n",
    "        \n",
    "#         best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "#         # saving best model\n",
    "#         torch.save(model.state_dict(), best_model_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7fbyTICtB/rCw/ahPljs8",
   "collapsed_sections": [],
   "name": "FNNMain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
